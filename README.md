# ğŸ§  IngestÃ£o e Busca SemÃ¢ntica com LangChain + Postgres (pgvector)

## ğŸš€ Objetivo
Este projeto permite:
- **IngestÃ£o:** Ler um arquivo `document.pdf`, quebrar em *chunks* (1000 tokens / 150 de overlap), gerar embeddings e salvar tudo no Postgres com **pgvector**.  
- **Busca:** Fazer perguntas via CLI e receber respostas **com base no conteÃºdo do PDF**, sem usar dados externos.

---

## ğŸ§© Tecnologias
- **Python 3.10+**
- **LangChain**
- **PostgreSQL + pgvector**
- **Docker & Docker Compose**
- **OpenAI** ou **Google Gemini** (para embeddings e chat)

---

## âš™ï¸ Requisitos
- Python 3.10 ou superior (se quiser rodar localmente)
- Docker e Docker Compose instalados
- Conta e chave de API da OpenAI (ou Google, se usar Gemini)

---

## ğŸ§° Estrutura do Projeto

```
ğŸ“¦ projeto/
â”œâ”€â”€ .env
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest.py
â”‚   â”œâ”€â”€ search.py
â”‚   â””â”€â”€ test_search.py
â””â”€â”€ document.pdf
```

---

## ğŸ”§ Arquivo `.env`

Crie um arquivo chamado `.env` na raiz do projeto com o conteÃºdo abaixo:

```bash
# ===== Banco de dados =====
# URL de conexÃ£o com o Postgres + pgvector
PGVECTOR_URL=postgresql+psycopg://postgres:postgres@127.0.0.1:5440/rag
# Nome da coleÃ§Ã£o onde os embeddings serÃ£o armazenados
PGVECTOR_COLLECTION=gpt5_collection

# ===== OpenAI (padrÃ£o) =====
# Sua chave de API da OpenAI (obrigatÃ³ria se usar o provedor OpenAI)
OPENAI_API_KEY=coloque_sua_chave_aqui
# Modelo de embeddings
OPENAI_MODEL=text-embedding-3-small
# Modelo de chat
OPENAI_CHAT_MODEL=gpt-5-nano

# ===== Gemini (opcional) =====
# Sua chave de API do Google (se for usar Gemini)
GOOGLE_API_KEY=
# Modelo de embeddings do Gemini
GEMINI_EMBEDDING_MODEL=models/embedding-001
# Modelo de chat do Gemini
GEMINI_CHAT_MODEL=gemini-2.5-flash-lite

# ===== Seletor de provedor =====
# Define qual provedor serÃ¡ usado: "openai" ou "gemini"
PROVIDER=openai
```

---

## ğŸ³ ğŸ’» Como Rodar o Projeto com Docker

### 1ï¸âƒ£ Subir o banco de dados com pgvector
Na raiz do projeto, execute:
```bash
docker compose up -d
```

Isso irÃ¡:
- Criar um container **Postgres 17 com a extensÃ£o pgvector**
- Expor a porta **5440**
- Criar o banco **rag**

Verifique se o container estÃ¡ ativo:
```bash
docker compose ps
```

E acesse o banco, se quiser conferir:
```bash
psql "postgresql://postgres:postgres@127.0.0.1:5440/rag"
```

---

### 2ï¸âƒ£ (Opcional) Rodar o Python dentro de um container
Se vocÃª quiser rodar a aplicaÃ§Ã£o dentro de um container Python (sem precisar instalar dependÃªncias localmente), adicione no seu `docker-compose.yml` algo como:

```yaml
services:
  app:
    build: .
    volumes:
      - .:/app
    depends_on:
      - postgres
    environment:
      - PGVECTOR_URL=${PGVECTOR_URL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PROVIDER=${PROVIDER}
    command: tail -f /dev/null
```

Depois suba novamente:
```bash
docker compose up -d --build
```

E entre no container para rodar os scripts:
```bash
docker exec -it app bash
```

---

### 3ï¸âƒ£ Rodar os scripts (no host ou no container)

**IngestÃ£o de documentos:**
```bash
python3 src/ingest.py
```
Isso vai:
- Ler o arquivo `document.pdf`
- Gerar os *chunks*
- Criar embeddings
- Inserir os vetores no Postgres (coleÃ§Ã£o definida no `.env`)

**Busca semÃ¢ntica (CLI):**
```bash
python3 src/test_search.py
```
O script farÃ¡ uma pergunta e mostrarÃ¡ a resposta com base nos dados vetorizados.

---

## ğŸ§° Comandos Ãšteis do Docker

| Comando | DescriÃ§Ã£o |
|----------|------------|
| `docker compose up -d` | Sobe os containers em background |
| `docker compose down` | Derruba todos os containers |
| `docker compose logs -f` | Mostra os logs em tempo real |
| `docker compose ps` | Mostra o status dos containers |
| `docker exec -it app bash` | Abre o shell dentro do container do app |
| `docker exec -it postgres bash` | Abre o shell dentro do Postgres |
| `psql "postgresql://postgres:postgres@127.0.0.1:5440/rag"` | Acessa o banco localmente |

---

## ğŸ§  Dicas Extras

- VocÃª pode armazenar vÃ¡rios PDFs e ajustar o `ingest.py` para processar todos de uma pasta `docs/`.
- Para usar o **Gemini** ao invÃ©s da **OpenAI**, altere no `.env`:
  ```bash
  PROVIDER=gemini
  ```

---

## ğŸ§¾ LicenÃ§a
MIT Â© 2025 â€” Desenvolvido por **Lucas Batista**
